{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "## Prerequisites\n",
    "To run the code, install the following packages. Please use the latest pre-release version `pip install azure-search-documents --pre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (11.4.0b9)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-search-documents) (1.29.4)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dschlesinger\\code\\ongoing\\openaiworkshop\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents --pre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\AOAI-workshop\\Lab #7a - Retrieval Augmented Generation with Azure Cognitive Search\\Lab #7a - Azure Cognitive Search Vector DB.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/AOAI-workshop/Lab%20%237a%20-%20Retrieval%20Augmented%20Generation%20with%20Azure%20Cognitive%20Search/Lab%20%237a%20-%20Azure%20Cognitive%20Search%20Vector%20DB.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtenacity\u001b[39;00m \u001b[39mimport\u001b[39;00m retry, wait_random_exponential, stop_after_attempt\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/AOAI-workshop/Lab%20%237a%20-%20Retrieval%20Augmented%20Generation%20with%20Azure%20Cognitive%20Search/Lab%20%237a%20-%20Azure%20Cognitive%20Search%20Vector%20DB.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# from azure.core.credentials import AzureKeyCredential\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/AOAI-workshop/Lab%20%237a%20-%20Retrieval%20Augmented%20Generation%20with%20Azure%20Cognitive%20Search/Lab%20%237a%20-%20Azure%20Cognitive%20Search%20Vector%20DB.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchClient\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/AOAI-workshop/Lab%20%237a%20-%20Retrieval%20Augmented%20Generation%20with%20Azure%20Cognitive%20Search/Lab%20%237a%20-%20Azure%20Cognitive%20Search%20Vector%20DB.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchIndexClient\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/AOAI-workshop/Lab%20%237a%20-%20Retrieval%20Augmented%20Generation%20with%20Azure%20Cognitive%20Search/Lab%20%237a%20-%20Azure%20Cognitive%20Search%20Vector%20DB.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Vector\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.search'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "# from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import Vector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment variables\n",
    "load_dotenv()\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\n",
    "    \"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# ---\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test embedding with langchain\n",
    "embeddingmodel = OpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME, chunk_size=1)\n",
    "vec = embeddingmodel.embed_query(\"transform to vec\")\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(page):\n",
    "    response = openai.Embedding.create(\n",
    "        input=page, engine=\"text-embedding-ada-002\")\n",
    "\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for loading into Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_title = \"Semantic Kernel\"\n",
    "# load pdf and split into pages\n",
    "fileName = \"../data/semantic-kernel.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split()\n",
    "print(\"Number of pages: \", len(pages))\n",
    "\n",
    "doc_with_vector_list = []\n",
    "doc_id = 0\n",
    "# Generate embeddings for title and content fields\n",
    "for page in pages:\n",
    "    page_with_vector = {}\n",
    "    page_with_vector['id'] = str(doc_id)\n",
    "    page_with_vector['title'] = doc_title\n",
    "    page_with_vector['titleVector'] = generate_embeddings(doc_title)\n",
    "    page_with_vector['content'] = page.page_content\n",
    "    page_with_vector['contentVector'] = generate_embeddings(page.page_content)\n",
    "    doc_with_vector_list.append(page_with_vector)\n",
    "    doc_id += 1\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"./sk_Vectors.json\", \"w\") as f:\n",
    "    json.dump(doc_with_vector_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "# Note: You must create Cognitive Search resource and get the endpoint and key in advance\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    # doc id - mandatory field\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True,\n",
    "                sortable=True, filterable=True, facetable=True),\n",
    "\n",
    "    # title and titleVector\n",
    "    SearchableField(\n",
    "        name=\"title\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"sk-vector-config\"),\n",
    "\n",
    "    # content and contentVector\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"sk-vector-config\"),\n",
    "\n",
    "]\n",
    "\n",
    "#The Hierarchical Navigable Small World (HNSW) graph algorithm is a popular method for approximate nearest neighbor search \n",
    "# in high-dimensional spaces.\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"sk-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,                  #maximum number of edges per node in the zero or base layer of the HNSW graph.\n",
    "                \"efConstruction\": 400,   #this parameter affects the index building during the construction phase.Increasing efConstruction will usually improve the quality of the constructed graph, leading to better recall. However, it will also slow down the index building process.\n",
    "                \"efSearch\": 500,         #this parameter affects the search time of the query phase. A higher value of efSearch increases the search time but usually results in better recall. \n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"sk-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=\"sk-cogsrch-vector-index-2\", fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload documents to the index\n",
    "with open('./sk_Vectors.json', 'r') as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(\n",
    "    endpoint=service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"semantic kernel?\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query),\n",
    "    top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search multi-lingual\n",
    "query = \"Planificador semántico del kernel y kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Cross-Field Vector Search with a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"programming languages supported by semantic kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"titleVector, contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\"] #searching on two fields title and content\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\",],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "print(type(results))\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    "    query_type=\"semantic\", query_language=\"en-us\", semantic_configuration_name='sk-semantic-config', query_caption=\"extractive\", query_answer=\"extractive\",\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
